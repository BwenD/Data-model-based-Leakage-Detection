import csv
import torch
import numpy as np
from torch.utils.data import Dataset
import matplotlib.pyplot as plt
import os
import time
import h5py
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import DataLoader

def get_adjacent_matrix(distance_file:str,num_nodes:int,id_file:str=None,graph_type='connect') -> np.array:
    A=np.zeros([int(num_nodes),int(num_nodes)])
    if id_file:
        with open(id_file,'r') as f_id:
            node_id_dict={int(node_id): idx for idx, node_id in enumerate(f_id.read().strip().split('\n'))}

            with open(distance_file,'r') as f_d:
                f_d.readline()
                reader=csv.reader(f_d)
                for item in reader:
                    if len(item) != 3:
                        continue
                    i, j, distance=int(item[0]), int(item[1]), float(item[2])
                    if graph_type=='connect':
                        A[node_id_dict[i],node_id_dict[j]]=1.
                        A[node_id_dict[j],node_id_dict[i]]=1.
                    elif graph_type=='distance':
                        A[node_id_dict[i],node_id_dict[j]]=1./distance
                        A[node_id_dict[j],node_id_dict[i]]=1./distance
                    else:
                        raise ValueError('graph type is not correct (connect or distance)')
        return A
    with open(distance_file,'r') as f_d:
        f_d.readline()
        reader=csv.reader(f_d)
        for item in reader:
            if len(item) != 3:
                continue
            i,j,distance=int(item[0]),int(item[1]),float(item[2])

            if graph_type=='connect':
                A[i,j],A[j,i]=1.,1.
            elif graph_type=='distance':
                A[i,j]=1./distance
                A[j,i]=1./distance
            else:
                raise ValueError('graph type is not correct (connect or distance)')
    return A

def get_pressure_data(pressure_file:str) -> np.array:
    original_data=np.load(pressure_file)
    pressure_data=original_data['arr_0']
    return pressure_data

class Evaluation(object):
    def __init__(self):
        pass
    @staticmethod
    def mae_(target,output):
        return np.mean(np.abs(target-output))
    @staticmethod
    def mape_(target,output):
        return np.mean(np.abs(target-output)/(target+0.000000001))
    @staticmethod
    def rmse_(target,output):
        return np.sqrt(np.mean(np.power(target-output,2)))
    @staticmethod
    def total(target,output):
        mae=Evaluation.mae_(target,output)
        mape=Evaluation.mape_(target,output)
        rmse=Evaluation.rmse_(target,output)
        return mae,mape,rmse

from matplotlib.pyplot import MultipleLocator
from matplotlib.font_manager import FontProperties

def visualize_result(h5_file, nodes_id,time_se,visualize_file):
    file_obj=h5py.File(h5_file,'r')
    prediction=file_obj['predict'][:][:,:,0]
    target=file_obj['target'][:][:,:,0]
    file_obj.close()
    plot_prediction=prediction[nodes_id][time_se[0]:time_se[1]]
    plot_target=target[nodes_id][time_se[0]:time_se[1]] 
    
    plt.figure(figsize=(20,4),dpi=600)
    plt.grid(True,linestyle='-.',linewidth=1.5)
    plt.scatter(np.array([t for t in range(time_se[1]-time_se[0])]), plot_target, ls='-', marker='o', color='darkorchid', s=10)
    plt.plot(np.array([t for t in range(time_se[1]-time_se[0])]), plot_prediction, ls='-', marker=' ', color='royalblue')    
   
    x1_major_locator=MultipleLocator(1000)
    y1_major_locator=MultipleLocator(0.6)

    ax1=plt.gca()
    ax1.spines['bottom'].set_linewidth(2)
    ax1.spines['left'].set_linewidth(2)
    ax1.spines['right'].set_linewidth(2)
    ax1.spines['top'].set_linewidth(2)
    
    ax1.xaxis.set_major_locator(x1_major_locator)
    ax1.yaxis.set_major_locator(y1_major_locator)
    
    
    font2={'family':'Times New Roman','weight':'normal','size':50}
    plt.xlabel('Timestamp',font2)  
    font3={'family':'Times New Roman','weight':'normal','size':50}
    plt.ylabel('Pressure',font3)
    
    font5 = {'family': 'Times New Roman', 'weight': 'normal', 'size': 40}
    font_prop1 = FontProperties(**font5)
    plt.legend(['Target','Prediction'], prop=font_prop1, loc='upper right')
    plt.axis([0,time_se[1]-time_se[0],np.min(np.array([np.min(plot_prediction),np.min(plot_target)])),np.max(np.array([np.max(plot_prediction),np.max(plot_target)]))])
    
    font4={'family':'Times New Roman','weight':'normal','size':40}
    font_prop = FontProperties(**font4)
    
    plt.xticks(fontproperties=font_prop, rotation=30)
    plt.yticks(fontproperties=font_prop)
    plt.savefig(visualize_file+'.png',bbox_inches='tight')
    
from chebnet import ChebNet

class LoadData(Dataset):
    def __init__(self,data_path,num_nodes,divide_days,time_interval,history_length,train_mode):
        self.data_path=data_path
        self.num_nodes=num_nodes
        self.train_mode=train_mode
        self.train_days=divide_days[0]
        self.test_days=divide_days[1]
        self.history_length=history_length
        self.time_interval=time_interval
        self.one_day_length=int(24*60/self.time_interval)
        self.graph=get_adjacent_matrix(distance_file=data_path[0],num_nodes=num_nodes)
        self.pressure_norm,self.pressure_data=self.pre_process_data(data=get_pressure_data(data_path[1]),norm_dim=1)
    def __len__(self):
        if self.train_mode=='train':
            return self.train_days*self.one_day_length-self.history_length        
        elif self.train_mode=='test':
            return self.test_days*self.one_day_length     
        else:
            raise ValueError('train mode: [{}] is not defined'.format(self.train_mode))
    def __getitem__(self,index):
        if self.train_mode=='train':
            index=index
        elif self.train_mode=='test':
            index+=self.train_days*self.one_day_length
        else:
            raise ValueError('train mode: [{}] is not defined'.format(self.train_mode))
        data_x,data_y=LoadData.slice_data(self.pressure_data,self.history_length,index,self.train_mode)
        data_x=LoadData.to_tensor(data_x)
        data_y=LoadData.to_tensor(data_y).unsqueeze(1)
        return {'graph':LoadData.to_tensor(self.graph),'pressure_x':data_x,'pressure_y':data_y}
    @staticmethod
    def slice_data(data, history_length, index, train_mode):
        if train_mode=='train':
            start_index=index
            end_index=index+history_length
        elif train_mode=='test':
            start_index=index-history_length
            end_index=index
        else:
            raise ValueError('train model {} is not defined'.format(train_mode))
        data_x=data[:, start_index:end_index]
        data_y=data[:, end_index]
        return data_x, data_y
    @staticmethod
    def pre_process_data(data,norm_dim):
        norm_base=LoadData.normalize_base(data, norm_dim)
        norm_data=LoadData.normalize_data(norm_base[0],norm_base[1],data)
        return norm_base, norm_data
    @staticmethod
    def normalize_base(data, norm_dim):
        max_data=np.max(data, norm_dim, keepdims=True)
        min_data=np.min(data,norm_dim,keepdims=True)
        return max_data, min_data
    @staticmethod
    def normalize_data(max_data, min_data, data):
        mid=min_data
        base=max_data-min_data
        normalized_data=(data-mid)/base
        return normalized_data
    @staticmethod
    def recover_data(max_data,min_data,data):
        mid=min_data
        base=max_data-min_data
        recovered_data=data*base+mid
        return recovered_data
    @staticmethod
    def to_tensor(data):
        return torch.tensor(data,dtype=torch.float)

def main():
    train_data = LoadData(data_path=['Pressure_Links2.csv', 'Pressure2.npz'], num_nodes=33, divide_days=[138,42], time_interval=5, history_length=6, train_mode='train')
    train_loader = DataLoader(train_data, batch_size=64, shuffle=True, num_workers=0)
    test_data = LoadData(data_path=['Pressure_Links2.csv', 'Pressure2.npz'], num_nodes=33, divide_days=[138,42], time_interval=5, history_length=6, train_mode='test')
    test_loader = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=0)
    my_net=ChebNet(in_c=6,hid_c=6,out_c=1,K=2)
    device = torch.device('cpu')
    my_net = my_net.to(device)
    criterion = nn.MSELoss()
    optimizer = optim.Adam(params=my_net.parameters(), lr=0.001)
    num_epochs = 15
    my_net.train()
    for epoch in range(num_epochs):
        epoch_loss = 0.0
        count = 0
        start_time = time.time()
        for data in train_loader:
            my_net.zero_grad()
            count += 1
            predict_value = my_net(data, device).to(torch.device('cpu'))
            loss = criterion(predict_value, data['pressure_y'])
            epoch_loss += loss.item()
            loss.backward()
            optimizer.step()
        end_time = time.time()
        print('Epoch:{:04d},Loss:{:02.4f},Time:{:02.2f} mins'.format(epoch, 1000*epoch_loss/len(train_data), (end_time-start_time)/60))
    my_net.eval()
    MAE, MAPE, RMSE = [], [], []
    Target = np.zeros([33, 1, 1])
    Predict = np.zeros_like(Target)
    total_loss = 0.0
    with torch.no_grad():
        for data in test_loader:
            predict_value = my_net(data, device).to(torch.device('cpu'))
            loss = criterion(predict_value, data['pressure_y'])
            total_loss += loss.item()
            predict_value = predict_value.transpose(0, 2).squeeze(0)
            target_value = data['pressure_y'].transpose(0, 2).squeeze(0)
            performance, data_to_save = compute_performance(predict_value, target_value, test_loader)
            Predict = np.concatenate([Predict, data_to_save[0]], axis=1)
            Target = np.concatenate([Target, data_to_save[1]], axis=1)
            MAE.append(performance[0])
            MAPE.append(performance[1])
            RMSE.append(performance[2])
        print('Test Loss:{:02.4f}'.format(1000*total_loss/len(test_data)))
    print('Performance: MAE{:2.4f}, MAPE{:2.4f}%, RMSE{:2.4f}'.format(np.mean(MAE), np.mean(MAPE)*100, np.mean(RMSE)))
    Predict = np.delete(Predict, 0, axis=1)
    Target = np.delete(Target, 0, axis=1)
    result_file = 'ChebNet_result'
    with h5py.File(result_file, 'w') as file_obj:
        file_obj['predict']=Predict
        file_obj['target']=Target
        file_obj.close()

def compute_performance(prediction,target,data):
    try:
        dataset=data.dataset
    except:
        dataset=data
    prediction=LoadData.recover_data(dataset.pressure_norm[0],dataset.pressure_norm[1],prediction.numpy())
    target=LoadData.recover_data(dataset.pressure_norm[0],dataset.pressure_norm[1],target.numpy())
    mae,mape,rmse=Evaluation.total(target.reshape(-1),prediction.reshape(-1))
    performance=[mae,mape,rmse]
    #visualize_metrics(mae, mape, rmse)
    recovered_data=[prediction,target]
    return performance,recovered_data

if __name__=='__main__':
    main()
    visualize_result(h5_file='ChebNet_result',nodes_id=32,time_se=[0,12096],visualize_file='ChebNet_node_5')
